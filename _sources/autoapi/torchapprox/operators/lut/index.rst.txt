:py:mod:`torchapprox.operators.lut`
===================================

.. py:module:: torchapprox.operators.lut


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   torchapprox.operators.lut.LUT




.. py:class:: LUT

   Bases: :py:obj:`torch.nn.Module`

   Class that wraps the Lookup Table matrix multiplication as a torch.nn.Module.
   This is required so that hooks can be attached in order to trace
   the quantized and unfolded input/output tensors at runtime

   .. py:property:: lut
      :type: Optional[torch.Tensor]

      The Lookup table to use for approximate multiplication. LUT can be:
      - `None`: An accurate product is used internall. This is much faster than passing
          operands through LUT kernels. Functionally equivalent to running the layer in
          `quant` mode, but useful when the unfolded inputs/outputs need to be traced at runtime.
      - `torch.Tensor` or `numpy.array`:
          - 2D array of size 256x256 is required. Unused entries will be ignored when simulating
              multiplication where the operand width is less than 8 Bit
          - When supplying a `torch.Tensor` the datatype needs to be signed 16-Bit.

   .. py:method:: forward(x: torch.Tensor, w: torch.Tensor, res: Optional[torch.Tensor] = None) -> torch.Tensor

      Perform Approximate Matrix Multiply (GeMM)

      :param x: Activations Tensor of dimension B x N x M
      :param w: Weight tensor of dimension K x M
      :param res: Pre-allocated output tensor

      :returns: The approximate matrix batched matrix product of x and w, using the supplied LUT



